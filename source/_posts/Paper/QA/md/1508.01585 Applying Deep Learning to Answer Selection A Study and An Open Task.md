---
title: 201508.01585 Applying Deep Learning to Answer Selection A Study and An Open Task
comments: true
date: 2017-10-13 13:58:15
updated: 2017-10-13 13:58:56
categories: QA
tags:
- QA
- QA Pair
---
个人评价：发布了InsuranceQA数据集，属于英文FAQ问题。使用CNN和polling与tanh的网络训练q与a的匹配得分模型。

<!-- more -->

原文：[201508.01585 Applying Deep Learning to Answer Selection A Study and An Open Task](201508.01585 Applying Deep Learning to Answer Selection A Study and An Open Task.pdf)

_IBM Watson_

## 摘要
- 提出通用的DL框架解决非仿真问题的QA。
- 创建了InsuranceQA数据集。
- Top1准确率在65%。

## 相关工作


- 常见qa思路：q和a语句分别训练vector，计算二者相似度。

## 数据集
* 自创建的[insuranceQA数据集](https://github.com/shuzi/insuranceQA)：采集互联网数据，创建insurance qa task，总共24,981问题。(验证集中各个问题只有500个答案的选择空间)


## 模型
- Baseline system：1. bag-of-words 基于词向量表示qa pair，计算cos相似度；2. IR information retrieval 使用WD weighted dependency model。这两个baseline与设计的模型进行比较。
- 提出基于CNN的模型：CNN的3个好处稀疏性、参数共享、变化表示(pooling等)。
	- 问题转换为vector，与filter卷积，输出得分最高的。
	- Train and loss：训练时使用A+(ground truth，正确的答案)和A-(negative answer，随机选取错误答案)，组成q、A+、A-进行训练，loss希望cos(q, A+)-cos(q, A-)最大，为了减少过拟合使用了P+T进行降维降幅。测试的时候利用学习好的网络计算所有候选a和q的cos最大的。
- 具体模型如下图所示。HL是hidden layer且用tanh激活(tanh(wx+b))，CNN进行卷积，P是Max-pooling，T是tanh激活。分别考虑是否共享参数、添加最后隐层、CNN层个数。结果表现是模型2最好。fine-tune特征数和层数、cnn包括skip-bigrams、使用GESD、AESD取代cos。GESD (Geometric mean of Euclidean and Sigmoid Dot product) and addition AESD (Arithmetic mean of Euclidean and Sigmoid Dot product)

## 实验
- 词向量初始化采用word2vec训练值。SGD优化。Loss中添加L2正则化项(也试验了L1-norm)。
- 结论：更好的结果—qa训练参数共享、层数更多、GESD和AESD。

![image](http://zcy.ckcest.cn/cdn/zy/20171012-Image-6.jpg)

QA用embedding初始化且不变，HL：hidden layer，CNN卷积，P：pooling，T：tanh激活，cos计算相似度，minibatch用一个正qa和499个负a最大化cos之和。
