---
title: 1710.00689 Building Chatbots from Forum Data Model Selection Using Question Answering Metrics
comments: true
date: 2017-10-13 13:58:15
updated: 2017-10-13 13:58:56
categories: QA
tags:
- QA
---
个人评价：用QA问答对训练seq2seq模型，讨论了模型训练的目标和答案相似度衡量的方法，但是称为“chatbot”不合适，相关工作完全没有上下文特性。
<!-- more -->

原文：[1710.00689 Building Chatbots from Forum Data Model Selection Using Question Answering Metrics](1710.00689 Building Chatbots from Forum Data Model Selection Using Question Answering Metrics.pdf)

## 概述
* 针对的问题训练chatbot的时候，使用seq2seq需要大量语料。没有语料的情况下如何进行训练呢，以及如何确定seq2seq模型的评估和选择。
* 本文使用的方法：获取整个Qatar网站的数据，加工成QA对，训练seq2seq作为chatbot模型，再用SemEval的CQA任务讨论训练seq2seq的训练策略。（注意SemEval的CQA任务的数据集就来自Qatar网站）

## 主要内容
* 数据加工：获取整个Qatar的数据加工成QA对，然后训练seq2seq模型作为chatbot模型。
	* 加工qa对的过程中，使用q和a向量的内积进行过滤，这样一来：q或a中一者有噪声或者q和a语义特征不显著的两种情况时的得分都会比较低，可过滤掉噪声和无意义数据。
* **如何确定模型训练的目标/停止条件**，即optimization for什么呢：
	* 训练目标是seq2seq的loss函数最小，只在训练集上即可，不包括验证集。
	* BLEU最高，计算生成的a和目标答案们之间的BLEU的均值。
	* MAP最高，_这地方我没看懂为什么论文表1中MAP和BLEU就一行，选用的排分策略是什么呢？_
	* 实验表明，优化MAP更好，优化BLEU偏向更长的答案。
* **如何确定答案的排分策略**：
	* 使用SemEval任务进行模型检验：模型产生答案，使用不同的相似性计算方法对答案rank，比较最终的MAP mean average precision，使用下列相似性计算方法排分a和候选a：
		* cos
		* BLEU，计算二者短语之间n元组共同出现的程度，越高越好，在个别语句上可能不好。
		* bm25，两个句子的相似度，算是tfidf的拓展。
		* TFIDF-based cos，代表的是tfidf应用到vector之后再计算cos
		* 以及上面几种都加上qc-sim再排分，其中qc-sim表示q和候选a之间的TFIDF-based cos。
	* 实验表明，`TFIDF-based cos + qc-sim`的排分准确定更好一些，BLEU不太好。